{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bikesharing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset and the libraries needed for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime, timedelta, date, time\n",
    "from haversine import haversine\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_la_2018 = pd.read_csv(\"data/la_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>end_station_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:04:00</td>\n",
       "      <td>2018-01-01 00:25:00</td>\n",
       "      <td>3063</td>\n",
       "      <td>3018</td>\n",
       "      <td>5889</td>\n",
       "      <td>Walk-up</td>\n",
       "      <td>Pershing Square</td>\n",
       "      <td>Grand &amp; Olympic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:05:00</td>\n",
       "      <td>2018-01-01 00:25:00</td>\n",
       "      <td>3063</td>\n",
       "      <td>3018</td>\n",
       "      <td>6311</td>\n",
       "      <td>Walk-up</td>\n",
       "      <td>Pershing Square</td>\n",
       "      <td>Grand &amp; Olympic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:06:00</td>\n",
       "      <td>2018-01-01 00:25:00</td>\n",
       "      <td>3063</td>\n",
       "      <td>3018</td>\n",
       "      <td>5753</td>\n",
       "      <td>Walk-up</td>\n",
       "      <td>Pershing Square</td>\n",
       "      <td>Grand &amp; Olympic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:13:00</td>\n",
       "      <td>2018-01-01 00:35:00</td>\n",
       "      <td>3018</td>\n",
       "      <td>3031</td>\n",
       "      <td>6220</td>\n",
       "      <td>Monthly Pass</td>\n",
       "      <td>Grand &amp; Olympic</td>\n",
       "      <td>7th &amp; Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:14:00</td>\n",
       "      <td>2018-01-01 00:59:00</td>\n",
       "      <td>4204</td>\n",
       "      <td>4216</td>\n",
       "      <td>12436</td>\n",
       "      <td>Monthly Pass</td>\n",
       "      <td>Washington &amp; Abbot Kinney</td>\n",
       "      <td>17th St / SMC E Line Station</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_time             end_time  start_station_id  end_station_id  \\\n",
       "0  2018-01-01 00:04:00  2018-01-01 00:25:00              3063            3018   \n",
       "1  2018-01-01 00:05:00  2018-01-01 00:25:00              3063            3018   \n",
       "2  2018-01-01 00:06:00  2018-01-01 00:25:00              3063            3018   \n",
       "3  2018-01-01 00:13:00  2018-01-01 00:35:00              3018            3031   \n",
       "4  2018-01-01 00:14:00  2018-01-01 00:59:00              4204            4216   \n",
       "\n",
       "   bike_id     user_type         start_station_name  \\\n",
       "0     5889       Walk-up            Pershing Square   \n",
       "1     6311       Walk-up            Pershing Square   \n",
       "2     5753       Walk-up            Pershing Square   \n",
       "3     6220  Monthly Pass            Grand & Olympic   \n",
       "4    12436  Monthly Pass  Washington & Abbot Kinney   \n",
       "\n",
       "               end_station_name  \n",
       "0               Grand & Olympic  \n",
       "1               Grand & Olympic  \n",
       "2               Grand & Olympic  \n",
       "3                  7th & Spring  \n",
       "4  17th St / SMC E Line Station  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_la_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some columns for the sake of convenience\n",
    "df_la_2018.rename(columns = {'start_station_id':'start_station'}, inplace = True)\n",
    "df_la_2018.rename(columns = {'end_station_id':'end_station'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 311894 entries, 0 to 311893\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   start_time          311894 non-null  object\n",
      " 1   end_time            311894 non-null  object\n",
      " 2   start_station       311894 non-null  int64 \n",
      " 3   end_station         311894 non-null  int64 \n",
      " 4   bike_id             311894 non-null  int64 \n",
      " 5   user_type           311894 non-null  object\n",
      " 6   start_station_name  311894 non-null  object\n",
      " 7   end_station_name    311894 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_la_2018.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Date related Features\n",
    "As we want to gain deep insight into the Bikesharing business at specific timeframes we want to generate additional date related features. We can do this by casting the start- and end time to pandas datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast start- & end_time to datetime \n",
    "\n",
    "df_la_2018[\"start_time\"] = pd.to_datetime(df_la_2018[\"start_time\"])\n",
    "df_la_2018[\"end_time\"] = pd.to_datetime(df_la_2018[\"end_time\"])\n",
    "\n",
    "#Add some Date related collumns to the dataframe\n",
    "df_la_2018[\"hour\"] = df_la_2018[\"start_time\"].apply(lambda x: x.hour)\n",
    "df_la_2018[\"week_day\"] = df_la_2018[\"start_time\"].apply(lambda x: x.weekday())\n",
    "df_la_2018[\"day\"] = df_la_2018[\"start_time\"].apply(lambda x: x.strftime(\"%d/%m/%Y\"))\n",
    "df_la_2018[\"month\"] = df_la_2018[\"start_time\"].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addional Datasets\n",
    "Additional data was available on the Los Angeles Bikeshare Metro website. We will use this data to improve our ability to visualize the data and predict future demand. Since the data was splitted into quarters, we must first combine it into a single data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>start_station</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>end_station</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>plan_duration</th>\n",
       "      <th>trip_route_category</th>\n",
       "      <th>passholder_type</th>\n",
       "      <th>bike_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>65406367</td>\n",
       "      <td>21</td>\n",
       "      <td>2018-01-01 00:04:00</td>\n",
       "      <td>2018-01-01 00:25:00</td>\n",
       "      <td>3063</td>\n",
       "      <td>34.049198</td>\n",
       "      <td>-118.252831</td>\n",
       "      <td>3018</td>\n",
       "      <td>34.043732</td>\n",
       "      <td>-118.260139</td>\n",
       "      <td>5889</td>\n",
       "      <td>0</td>\n",
       "      <td>One Way</td>\n",
       "      <td>Walk-up</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>65406366</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-01-01 00:05:00</td>\n",
       "      <td>2018-01-01 00:25:00</td>\n",
       "      <td>3063</td>\n",
       "      <td>34.049198</td>\n",
       "      <td>-118.252831</td>\n",
       "      <td>3018</td>\n",
       "      <td>34.043732</td>\n",
       "      <td>-118.260139</td>\n",
       "      <td>6311</td>\n",
       "      <td>0</td>\n",
       "      <td>One Way</td>\n",
       "      <td>Walk-up</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65406365</td>\n",
       "      <td>19</td>\n",
       "      <td>2018-01-01 00:06:00</td>\n",
       "      <td>2018-01-01 00:25:00</td>\n",
       "      <td>3063</td>\n",
       "      <td>34.049198</td>\n",
       "      <td>-118.252831</td>\n",
       "      <td>3018</td>\n",
       "      <td>34.043732</td>\n",
       "      <td>-118.260139</td>\n",
       "      <td>5753</td>\n",
       "      <td>0</td>\n",
       "      <td>One Way</td>\n",
       "      <td>Walk-up</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>65406364</td>\n",
       "      <td>22</td>\n",
       "      <td>2018-01-01 00:13:00</td>\n",
       "      <td>2018-01-01 00:35:00</td>\n",
       "      <td>3018</td>\n",
       "      <td>34.043732</td>\n",
       "      <td>-118.260139</td>\n",
       "      <td>3031</td>\n",
       "      <td>34.044701</td>\n",
       "      <td>-118.252441</td>\n",
       "      <td>6220</td>\n",
       "      <td>30</td>\n",
       "      <td>One Way</td>\n",
       "      <td>Monthly Pass</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>65406362</td>\n",
       "      <td>45</td>\n",
       "      <td>2018-01-01 00:14:00</td>\n",
       "      <td>2018-01-01 00:59:00</td>\n",
       "      <td>4204</td>\n",
       "      <td>33.988419</td>\n",
       "      <td>-118.451630</td>\n",
       "      <td>4216</td>\n",
       "      <td>34.023392</td>\n",
       "      <td>-118.479637</td>\n",
       "      <td>12436</td>\n",
       "      <td>30</td>\n",
       "      <td>One Way</td>\n",
       "      <td>Monthly Pass</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   trip_id  duration           start_time             end_time  \\\n",
       "0      0  65406367        21  2018-01-01 00:04:00  2018-01-01 00:25:00   \n",
       "1      1  65406366        20  2018-01-01 00:05:00  2018-01-01 00:25:00   \n",
       "2      2  65406365        19  2018-01-01 00:06:00  2018-01-01 00:25:00   \n",
       "3      3  65406364        22  2018-01-01 00:13:00  2018-01-01 00:35:00   \n",
       "4      4  65406362        45  2018-01-01 00:14:00  2018-01-01 00:59:00   \n",
       "\n",
       "   start_station  start_lat   start_lon  end_station    end_lat     end_lon  \\\n",
       "0           3063  34.049198 -118.252831         3018  34.043732 -118.260139   \n",
       "1           3063  34.049198 -118.252831         3018  34.043732 -118.260139   \n",
       "2           3063  34.049198 -118.252831         3018  34.043732 -118.260139   \n",
       "3           3018  34.043732 -118.260139         3031  34.044701 -118.252441   \n",
       "4           4204  33.988419 -118.451630         4216  34.023392 -118.479637   \n",
       "\n",
       "   bike_id  plan_duration trip_route_category passholder_type bike_type  \n",
       "0     5889              0             One Way         Walk-up       NaN  \n",
       "1     6311              0             One Way         Walk-up       NaN  \n",
       "2     5753              0             One Way         Walk-up       NaN  \n",
       "3     6220             30             One Way    Monthly Pass       NaN  \n",
       "4    12436             30             One Way    Monthly Pass       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_la_q1 = pd.read_csv(\"data/metro-bike-share-trips-2018-q1.csv\")\n",
    "df_la_q2 = pd.read_csv(\"data/metro-bike-share-trips-2018-q2.csv\")\n",
    "df_la_q3 = pd.read_csv(\"data/metro-bike-share-trips-2018-q3.csv\")\n",
    "df_la_q4 = pd.read_csv(\"data/metro-bike-share-trips-2018-q4.csv\")\n",
    "df_la_2018_extension = pd.concat([df_la_q1,df_la_q2,df_la_q3,df_la_q4])\n",
    "df_la_2018_extension = df_la_2018_extension.reset_index()\n",
    "df_la_2018_extension.drop(\"index\", axis=1)\n",
    "df_la_2018_extension.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data in the extension set\n",
    "As we can see, there are some columns with missing data (null values). The affected columns include: start_lat, start_lon, end_lat, end_lon and bike_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 311894 entries, 0 to 311893\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   index                311894 non-null  int64  \n",
      " 1   trip_id              311894 non-null  int64  \n",
      " 2   duration             311894 non-null  int64  \n",
      " 3   start_time           311894 non-null  object \n",
      " 4   end_time             311894 non-null  object \n",
      " 5   start_station        311894 non-null  int64  \n",
      " 6   start_lat            311146 non-null  float64\n",
      " 7   start_lon            311146 non-null  float64\n",
      " 8   end_station          311894 non-null  int64  \n",
      " 9   end_lat              306771 non-null  float64\n",
      " 10  end_lon              306771 non-null  float64\n",
      " 11  bike_id              311894 non-null  int64  \n",
      " 12  plan_duration        311894 non-null  int64  \n",
      " 13  trip_route_category  311894 non-null  object \n",
      " 14  passholder_type      311894 non-null  object \n",
      " 15  bike_type            73867 non-null   object \n",
      "dtypes: float64(4), int64(7), object(5)\n",
      "memory usage: 38.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_la_2018_extension.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add the duration feature directly, since it does not contain null values.\n",
    "df_la_2018[\"duration\"] = df_la_2018_extension[\"duration\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A look at the units with missing coordinates reveals that these enteties belong to a specific bike station (3000). According to the Bikeshare Metro website, this station is a \"Virtual Station\" used by employees to check in or check out a bike remotely for a special event or in a situation in which a bike could not otherwise be checked in or out to a station. As we want to gain knowledge about popular routes and disttances driven, we need the start/end coordinates of a trip as a tuple. Since no start/end coordinates are specified for the entities with start/end station 3000, we decided to fill these entities assuming that the missing values correspond to the existing values (start/end station specified). Since we cannot use haversine when the starting station is equal to the ending station, we decided that the time traveled divided by the average speed could be a valid value for calculating the distance traveled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-20-ecc5db1ec788>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-ecc5db1ec788>\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Combine longitude/latitude\n",
    "\n",
    "df_la_2018_extension[\"start_coordinates\"] = list(zip(df_la_2018_extension[\"start_lat\"].round(4),df_la_2018_extension[\"start_lon\"].round(4)))\n",
    "df_la_2018_extension[\"end_coordinates\"] = list(zip(df_la_2018_extension[\"end_lat\"].round(4),df_la_2018_extension[\"end_lon\"].round(4)))\n",
    "\n",
    "#Add Collums to the original Dataframe\n",
    "\n",
    "df_la_2018[\"start_coordinates\"] = df_la_2018_extension[\"start_coordinates\"]\n",
    "df_la_2018[\"end_coordinates\"] = df_la_2018_extension[\"end_coordinates\"]\n",
    "\n",
    "#Calculating the distances driven (using Haversine if the coordinates are available) OTHERWISE -1 IS RETURNED!\n",
    "\n",
    "def calculateDistance(x):\n",
    "    if(math.isnan(x[\"start_coordinates\"][0])|math.isnan(x[\"start_coordinates\"][1])|math.isnan(x[\"end_coordinates\"][0])|math.isnan(x[\"end_coordinates\"][1])|(x[\"start_coordinates\"]==x[\"end_coordinates\"])): return -1\n",
    "    return haversine(x[\"start_coordinates\"], x[\"end_coordinates\"])\n",
    "\n",
    "df_la_2018[\"distance\"] = df_la_2018.apply(lambda x: calculateDistance(x), axis=1)\n",
    "\n",
    "#Calculate the speed IF THE DISTANCE IS != -1 OTHERWISE 12 IS RETURNED!\n",
    "\n",
    "def calculateSpeed(x):\n",
    "    if(x[\"distance\"]!=-1): return (x[\"distance\"]/(x[\"duration\"]/60)\n",
    "    return 12\n",
    "        \n",
    "df_la_2018[\"km/h\"] = df_la_2018.apply(lambda x: calculateSpeed(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another factor of interest is the type of bike ridden, as prices differ between standard and electric bikes. We found that for some entitie we can draw conclusions about the bike_type, since some bike_id's provide information about what type of bike it is. Unfortunately, this is not the case for all entities, so we assumed that the missing values correspond to the more common standard bike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The unique ID's of bikes for which the type is specified \n",
    "bike_ids_with_type = df_la_2018_extension[pd.isna(df_la_2018_extension[\"bike_type\"])==False][\"bike_id\"].unique()\n",
    "\n",
    "# The unique ID's of bikes for which the type isnt specified \n",
    "bike_ids_without_type = df_la_2018_extension[pd.isna(df_la_2018_extension[\"bike_type\"])][\"bike_id\"].unique()\n",
    "\n",
    "# If the arrays are equal, we can infer each individual bike_type\n",
    "print(np.array_equal(bike_ids_with_type, bike_ids_without_type))\n",
    "np.setdiff1d(bike_ids_without_type, bike_ids_with_type, assume_unique=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_type_by_id = df_la_2018_extension[pd.isna(df_la_2018_extension[\"bike_type\"])==False][[\"bike_id\",\"bike_type\"]]\n",
    "\n",
    "def getBikeType(id):\n",
    "    return bike_type_by_id[bike_type_by_id[\"bike_id\"]==id][\"bike_type\"].unique()\n",
    "\n",
    "def fillMissingBikeTypes(x):\n",
    "\n",
    "    if(pd.isna(x[\"bike_type\"])):\n",
    "        if(x[\"bike_id\"] in bike_ids_with_type):\n",
    "             return getBikeType(x[\"bike_id\"])[0]\n",
    "        else: return \"standard\"\n",
    "    return x[\"bike_type\"]\n",
    "    \n",
    "df_la_2018_extension[\"bike_type\"] = df_la_2018_extension.apply(lambda x: fillMissingBikeTypes(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_la_2018_extension.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the \"bike_type\" column does not contain null values anymore, we can now add it to the original data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_la_2018[\"bike_type\"] = df_la_2018_extension[\"bike_type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping outliers and redundant features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_la_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop enteties with start- & end station 3000 as they dont represent customer rides\n",
    "df_la_2018.drop(df_la_2018[(df_la_2018[\"start_station\"]==3000)&(df_la_2018[\"end_station\"]==3000)].index, inplace=True)\n",
    "\n",
    "#Drop rides with > 25 kmh \n",
    "df_la_2018.drop(df_la_2018[df_la_2018[\"km/h\"]>25].index, inplace=True)\n",
    "\n",
    "#Drop start_station_name & start_station_name as we can identifie the station by its id \n",
    "df_la_2018.drop([\"start_station_name\", \"end_station_name\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_la_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_la_2018.to_pickle(\"Data/df_la_2018.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
